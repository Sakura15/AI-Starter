{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Transformer Network (Image Classification)\n",
    "\n",
    "Chúng ta từng biết nhiều biến thể CNN và ứng dụng CNN trong nhiều bài toán. Một dạng biến thể CNN đó là: Spatial Transformer Network (Image Classification).\n",
    "\n",
    "### What is the Spatial Transformer Network (Image Classification)?\n",
    "\n",
    "STN giúp cắt, scale đầu vào mục đích làm sự đa dạng đầu vào giúp tăng hiệu suất của mô hình phân loại. Nhưng khác với data agument STN tác độc trên từng điểm ảnh thay vì trên toàn bộ cả ảnh.\n",
    "\n",
    "![](https://miro.medium.com/max/1200/1*P_nv_a_Q3LqM9d10XGE3TQ.gif)\n",
    "### How it work?\n",
    "\n",
    "Tư tưởng chính của STN sử dụng phép biến đổi hình ảnh.\n",
    "\n",
    "+ Biến đổi Affine\n",
    "\n",
    "Là phép biến đổi tọa độ tức trên từng điểm. \n",
    "Biến đổi Affine là 1 thuật toán được học trong môn kĩ thuật đồ họa với ai học tại Học Viện CNBCVT. Bài toán phát biển. Với một điểm, đường thẳng biến đổi nó kích thước tăng lên 2 lần, xoay góc 45 độ, thua nhỏ, dịch đi đoạn là c...\n",
    "\n",
    "Với điểm (x1,y1) chúng ta biến đổi thành (x2,y2)\n",
    "Điều đó biến đổi nhờ ma trận trận chuyển đổi:\n",
    "Ma trận biến đổi: T = [[a, c], [b, d]]\n",
    "\n",
    "[x2 y2] =  [x1 y1] * T = [x1*a + c*y1  x1*b + d*y1] \n",
    "\n",
    "   * Bất biến  a == d == 1 và c == b == 0\n",
    "   * Phép tỉ lệ a = hệ số tỉ lệ theo trục x , d hệ số tỉ lệ theo trục y  \n",
    "   * Phép dịch chuyển: \n",
    "   * Phép xoay góc anpha: a == d==cos(anpha);  b == -c == sin(anpha) \n",
    "\n",
    "+ Biến đổi Projective\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*07ai6mvHOBKyIhedj5YwHg.png)\n",
    "\n",
    "+ Biển đổi TPS) Transformation\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*yBeuq1ViVf4McTHonosusQ.png)\n",
    "\n",
    "Kết quả biến đổi TPS:\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/1278/1*ZSbO6OsydMhQxsRpIaWdXQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vậy với phép biến đổi kia mạng học thế nào nếu sử dụng phép biến đổi trên? \n",
    "\n",
    "Tất cả tham số a, b, c, d đối vs phép biến đổi ban đầu, hay thêm Gi, Fi của TPS. Điều này tương đương với các kerner chập lên đầu vào các tham số a, b,c ,d sẽ được học trong lần trainning. \n",
    "\n",
    "Thay vì rút trích đặc trưng như Conv thông thường, sử dụng phép biển đổi này nó giúp chúng ta học được nhưng dữ liệu được biến đổi đi, chẳng hạn người nay bị động kinh nên méo mặt, hay bị tai nạn nên xưng mặt lên thì áp dụng phép biến đổi này như kenerl cho mô hình mạng Conv thông thường thì sẽ có hiệu quả nhất định.\n",
    "\n",
    "### Mạng biến áp không gian STN\n",
    "\n",
    "Sơ đồ tổng quan cấu trúc mạng STN\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*Nkp0wGEurUuYPmqPR0WgpA.png)\n",
    "\n",
    "\n",
    "STN bao gồm Localization Net , Grid Generator và Sampler.\n",
    "\n",
    "Chúng ta khám phá từng phần của STN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Localisation Net\n",
    "\n",
    "Input feature map U với chiều rộng w, cao h, kênh là c (có thể là ảnh RGB) outputs are θ. Tại đây nó sẽ học xem nên sử dụng phép biến đổi nào, tức là sử dụng ma trận ra sao. Nó có thể là ma trận biến đổi như affine hay TPS nhưng chủ yếu đươc giới hạn phép tỉ lệ hoặc phép dịch\n",
    "\n",
    "![](https://miro.medium.com/max/200/1*HlR5Uv_EkT1lA7BUsOINVA.png)\n",
    "\n",
    "* Grid Generator\n",
    "\n",
    "Tại đây với nhưng phép biển đổi học được nó áp dụng lên tập dữ liệu hình thành nên những dữ liệu mới, hay các thực hiện biến đổi các bức ảnh đầu vào thành bức ảnh mới.  Số lượng phép biến đổi phụ thuộc và θ đã được học trong giai đoạn trước.\n",
    "\n",
    "* Sampler\n",
    "\n",
    "![](https://miro.medium.com/max/2000/1*X_sFuFAdRmT_kUMQ9wNBjg.png)\n",
    "\n",
    "Dựa trên bộ mới của tọa độ (xt_i, yt_i), chúng tôi tạo ra một biến đổi đầu ra bản đồ tính năng V . Tập V này được dịch, thu nhỏ, xoay, vênh, biến đổi hoặc chiếu, bất cứ điều gì.\n",
    "\n",
    "Cần lưu ý rằng STN có thể được áp dụng cho không chỉ hình ảnh đầu vào, mà cả các bản đồ tính năng trung gian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như vậy nhờ áp dụng STN chúng ta có dữ liệu mới hiệu quả hơn cho phân loại xem ví dụ sau hiểu rõ hơn\n",
    "\n",
    "![](https://miro.medium.com/max/2000/1*kAmJ1-USO_bTWtu4vumk7g.png)\n",
    "\n",
    "Một vài kết quả thí nghiệp: \n",
    "\n",
    "![](https://miro.medium.com/max/2000/1*mKpIx9-S232dRL7CB8ZW3w.png)\n",
    "\n",
    "\n",
    "TC : dịch và lộn xộn, R : xoay, RTS : xoay, dịch và chia tỷ lệ, P : biến dạng chiếu, E : biến dạng đàn hồi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiện tại nó đã được public thành APi và dễ dàng cài đặt:\n",
    "\n",
    "pip3 install stn\n",
    "\n",
    "\n",
    "Cách gọi:\n",
    "    \n",
    "from stn import spatial_transformer_network as transformer\n",
    "\n",
    "out = transformer(input_feature_map, theta, out_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "\n",
    "    def K_meshgrid(x, y):\n",
    "        return tf.meshgrid(x, y)\n",
    "\n",
    "    def K_linspace(start, stop, num):\n",
    "        return tf.linspace(start, stop, num)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Only 'tensorflow' is supported as backend\")\n",
    "\n",
    "\n",
    "class BilinearInterpolation(Layer):\n",
    "    \"\"\"Performs bilinear interpolation as a keras layer\n",
    "    References\n",
    "    ----------\n",
    "    [1]  Spatial Transformer Networks, Max Jaderberg, et al.\n",
    "    [2]  https://github.com/skaae/transformer_network\n",
    "    [3]  https://github.com/EderSantana/seya\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size, **kwargs):\n",
    "        self.output_size = output_size\n",
    "        super(BilinearInterpolation, self).__init__(**kwargs)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'output_size': self.output_size,\n",
    "        }\n",
    "\n",
    "    def compute_output_shape(self, input_shapes):\n",
    "        height, width = self.output_size\n",
    "        num_channels = input_shapes[0][-1]\n",
    "        return (None, height, width, num_channels)\n",
    "\n",
    "    def call(self, tensors, mask=None):\n",
    "        X, transformation = tensors\n",
    "        output = self._transform(X, transformation, self.output_size)\n",
    "        return output\n",
    "\n",
    "    def _interpolate(self, image, sampled_grids, output_size):\n",
    "\n",
    "        batch_size = K.shape(image)[0]\n",
    "        height = K.shape(image)[1]\n",
    "        width = K.shape(image)[2]\n",
    "        num_channels = K.shape(image)[3]\n",
    "\n",
    "        x = K.cast(K.flatten(sampled_grids[:, 0:1, :]), dtype='float32')\n",
    "        y = K.cast(K.flatten(sampled_grids[:, 1:2, :]), dtype='float32')\n",
    "\n",
    "        x = .5 * (x + 1.0) * K.cast(width, dtype='float32')\n",
    "        y = .5 * (y + 1.0) * K.cast(height, dtype='float32')\n",
    "\n",
    "        x0 = K.cast(x, 'int32')\n",
    "        x1 = x0 + 1\n",
    "        y0 = K.cast(y, 'int32')\n",
    "        y1 = y0 + 1\n",
    "\n",
    "        max_x = int(K.int_shape(image)[2] - 1)\n",
    "        max_y = int(K.int_shape(image)[1] - 1)\n",
    "\n",
    "        x0 = K.clip(x0, 0, max_x)\n",
    "        x1 = K.clip(x1, 0, max_x)\n",
    "        y0 = K.clip(y0, 0, max_y)\n",
    "        y1 = K.clip(y1, 0, max_y)\n",
    "\n",
    "        pixels_batch = K.arange(0, batch_size) * (height * width)\n",
    "        pixels_batch = K.expand_dims(pixels_batch, axis=-1)\n",
    "        flat_output_size = output_size[0] * output_size[1]\n",
    "        base = K.repeat_elements(pixels_batch, flat_output_size, axis=1)\n",
    "        base = K.flatten(base)\n",
    "\n",
    "        # base_y0 = base + (y0 * width)\n",
    "        base_y0 = y0 * width\n",
    "        base_y0 = base + base_y0\n",
    "        # base_y1 = base + (y1 * width)\n",
    "        base_y1 = y1 * width\n",
    "        base_y1 = base_y1 + base\n",
    "\n",
    "        indices_a = base_y0 + x0\n",
    "        indices_b = base_y1 + x0\n",
    "        indices_c = base_y0 + x1\n",
    "        indices_d = base_y1 + x1\n",
    "\n",
    "        flat_image = K.reshape(image, shape=(-1, num_channels))\n",
    "        flat_image = K.cast(flat_image, dtype='float32')\n",
    "        pixel_values_a = K.gather(flat_image, indices_a)\n",
    "        pixel_values_b = K.gather(flat_image, indices_b)\n",
    "        pixel_values_c = K.gather(flat_image, indices_c)\n",
    "        pixel_values_d = K.gather(flat_image, indices_d)\n",
    "\n",
    "        x0 = K.cast(x0, 'float32')\n",
    "        x1 = K.cast(x1, 'float32')\n",
    "        y0 = K.cast(y0, 'float32')\n",
    "        y1 = K.cast(y1, 'float32')\n",
    "\n",
    "        area_a = K.expand_dims(((x1 - x) * (y1 - y)), 1)\n",
    "        area_b = K.expand_dims(((x1 - x) * (y - y0)), 1)\n",
    "        area_c = K.expand_dims(((x - x0) * (y1 - y)), 1)\n",
    "        area_d = K.expand_dims(((x - x0) * (y - y0)), 1)\n",
    "\n",
    "        values_a = area_a * pixel_values_a\n",
    "        values_b = area_b * pixel_values_b\n",
    "        values_c = area_c * pixel_values_c\n",
    "        values_d = area_d * pixel_values_d\n",
    "        return values_a + values_b + values_c + values_d\n",
    "\n",
    "    def _make_regular_grids(self, batch_size, height, width):\n",
    "        # making a single regular grid\n",
    "        x_linspace = K_linspace(-1., 1., width)\n",
    "        y_linspace = K_linspace(-1., 1., height)\n",
    "        x_coordinates, y_coordinates = K_meshgrid(x_linspace, y_linspace)\n",
    "        x_coordinates = K.flatten(x_coordinates)\n",
    "        y_coordinates = K.flatten(y_coordinates)\n",
    "        ones = K.ones_like(x_coordinates)\n",
    "        grid = K.concatenate([x_coordinates, y_coordinates, ones], 0)\n",
    "\n",
    "        # repeating grids for each batch\n",
    "        grid = K.flatten(grid)\n",
    "        grids = K.tile(grid, K.stack([batch_size]))\n",
    "        return K.reshape(grids, (batch_size, 3, height * width))\n",
    "\n",
    "    def _transform(self, X, affine_transformation, output_size):\n",
    "        batch_size, num_channels = K.shape(X)[0], K.shape(X)[3]\n",
    "        transformations = K.reshape(affine_transformation,\n",
    "                                    shape=(batch_size, 2, 3))\n",
    "        # transformations = K.cast(affine_transformation[:, 0:2, :], 'float32')\n",
    "        regular_grids = self._make_regular_grids(batch_size, *output_size)\n",
    "        sampled_grids = K.batch_dot(transformations, regular_grids)\n",
    "        interpolated_image = self._interpolate(X, sampled_grids, output_size)\n",
    "        new_shape = (batch_size, output_size[0], output_size[1], num_channels)\n",
    "        interpolated_image = K.reshape(interpolated_image, new_shape)\n",
    "        return interpolated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n",
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_initial_weights(output_size):\n",
    "    b = np.zeros((2, 3), dtype='float32')\n",
    "    b[0, 0] = 1\n",
    "    b[1, 1] = 1\n",
    "    W = np.zeros((output_size, 6), dtype='float32')\n",
    "    print(W.shape)\n",
    "    print(b.shape)\n",
    "    weights = [W, b.flatten()]\n",
    "    return weights\n",
    "\n",
    "weights =  get_initial_weights(50)\n",
    "np.array(weights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STN(input_shape=(60, 60, 1), sampling_size=(30, 30), num_classes=10):\n",
    "    image = Input(shape=input_shape)\n",
    "    locnet = MaxPool2D(pool_size=(2, 2))(image)\n",
    "    locnet = Conv2D(20, (5, 5))(locnet)\n",
    "    locnet = MaxPool2D(pool_size=(2, 2))(locnet)\n",
    "    locnet = Conv2D(20, (5, 5))(locnet)\n",
    "    locnet = Flatten()(locnet)\n",
    "    locnet = Dense(50)(locnet)\n",
    "    locnet = Activation('relu')(locnet)\n",
    "    weights = get_initial_weights(50)\n",
    "    locnet = Dense(6, weights=weights)(locnet)\n",
    "    x = BilinearInterpolation(sampling_size)([image, locnet])\n",
    "    x = Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dense(num_classes)(x)\n",
    "    x = Activation('softmax')(x)\n",
    "    return Model(inputs=image, outputs=x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
